import json
import datetime
from fastapi import FastAPI, HTTPException , Request
from pydantic import BaseModel
from typing import List, Dict

from core.inferencer import Inferencer
import llm_tools.math
import llm_tools.eth

# è®¾ç½® API å¯†é’¥
API_KEY = "123"

# åˆå§‹åŒ– Inferencer
print("Initializing Inferencer...")
tools = []
tools.extend(llm_tools.math.math_tools)
tools.extend(llm_tools.eth.eth_tools)

inferencer = Inferencer(
    model_config={"model_name": "Qwen/Qwen3-1.7B"},
    tools=tools,
    thinking=True
)
print("Inferencer initialized.")

# FastAPI åº”ç”¨
app = FastAPI(
    title="Custom Inferencer API",
    description="Qwen3 + Tools for Open WebUI",
    version="1.0.0"
)

# è¾“å…¥æ•°æ®ç»“æ„
class ChatInput(BaseModel):
    messages: List[Dict[str, str]]
    api_key: str

# æ¨ç†æ¥å£ï¼šåŒæ—¶å…¼å®¹ 2 ä¸ªè·¯å¾„
@app.post("/infer")
@app.post("/infer/chat/completions")
async def infer_openai_compatible(request: Request):
    body = await request.json()
    messages = body.get("messages", [])
    print("ğŸ”¥ OpenAI-style messages:", messages)

    if not messages:
        raise HTTPException(status_code=400, detail="Missing messages")

    if not any(msg["role"] == "system" for msg in messages):
        messages.insert(0, {
            "role": "system",
            "content": f"You are a helpful assistant with tools. {datetime.datetime.now()}"
        })

    response = inferencer.infer(messages)
    return {"choices": [{"message": response[-1]}]}

# æ¨¡å‹åˆ—è¡¨æ¥å£ï¼ˆæ— éœ€å¯†é’¥ï¼‰
@app.get("/infer/models")
async def list_models():
    return {"models": ["Qwen/Qwen3-1.7B"]}
